# Assistente LLM Especializado com FastAPI e Gemini

## üéØ Objetivo do Projeto

Este projeto implementa um **microservi√ßo em Python utilizando o framework FastAPI** que atua como um assistente inteligente especializado. O assistente √© focado em **boas pr√°ticas de programa√ß√£o Python e no framework FastAPI**.

A API se integra com o modelo de linguagem **Gemini 2.5 Flash** da Google, utilizando o SDK oficial `google-genai`. O principal diferencial √© a implementa√ß√£o de um **contexto conversacional simples** (hist√≥rico de chat) mantido em mem√≥ria, atendendo aos requisitos da **Trilha A ‚Äì Assistente LLM**.

## üõ†Ô∏è Tecnologias Utilizadas

*   **Backend:** Python 3.11+
*   **Framework Web:** FastAPI
*   **Gera√ß√£o de IA:** Google Gemini API (modelo `gemini-2.5-flash`)
*   **Gerenciamento de Depend√™ncias:** `requirements.txt`
*   **Vari√°veis de Ambiente:** `python-dotenv`

## ‚öôÔ∏è Instru√ß√µes de Instala√ß√£o

1.  **Crie e ative um ambiente virtual (recomendado):**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # No Linux/macOS
     venv\Scripts\activate  # No Windows
    ```

2.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Obtenha sua Chave de API do Gemini:**
    *   Crie uma conta no Google AI Studio e gere sua chave de API.
    *   Acesse: [Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key)

4.  **Configure a Vari√°vel de Ambiente:**
    - V√° no arquivo `.env` na raiz do projeto e adicione sua chave de API:
    ```
    GEMINI_API_KEY="SUA_CHAVE_DE_API_AQUI"
    ```
    - Como usar

- Defina a vari√°vel de ambiente GEMINI_API_KEY antes de iniciar o servidor:
- No proprio Powershell antes de inicializar o servidor coloque a chave nas "" 
```
$env:GEMINI_API_KEY="SUA_CHAVE-API"
```
- O projeto utiliza a biblioteca `python-dotenv` para carregar essa vari√°vel automaticamente.

## ‚ñ∂Ô∏è Como Rodar o Servidor

Com o ambiente virtual ativado e as depend√™ncias instaladas, execute o servidor Uvicorn:

```bash
uvicorn main:app --reload
```

O servidor estar√° acess√≠vel em `http://127.0.0.1:8000`.

## üß™ Como Testar as Rotas

A documenta√ß√£o interativa (Swagger UI) est√° dispon√≠vel em: `http://127.0.0.1:8000/docs`.

### 1. Rota Principal: `/chat` (POST)

Esta rota √© respons√°vel pela intera√ß√£o com o assistente LLM, mantendo o contexto conversacional.

**Endpoint:** `POST /chat`

**Corpo da Requisi√ß√£o (JSON):**

| Campo | Tipo | Descri√ß√£o | Exemplo |
| :--- | :--- | :--- | :--- |
| `user_id` | `string` | Identificador √∫nico para a sess√£o de chat (necess√°rio para manter o hist√≥rico). | `"usuario_teste_123"` |
| `message` | `string` | A mensagem a ser enviada ao assistente. | `"Qual a diferen√ßa entre Pydantic BaseModel e dataclasses?"` |

**Exemplo de Teste com `curl`:**

```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/chat' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "user_id": "dev_001",
  "message": "Qual a diferen√ßa entre Pydantic BaseModel e dataclasses?"
}'
```

**Resposta Esperada (JSON):**

```json
{
  "user_id": "dev_001",
  "response": "O Pydantic BaseModel √© focado em valida√ß√£o de dados e serializa√ß√£o/desserializa√ß√£o, sendo ideal para APIs (como no FastAPI). J√° o dataclass √© uma ferramenta nativa do Python para criar classes com foco em armazenamento de dados, sem a valida√ß√£o autom√°tica do Pydantic.",
  "history_length": 2
}
```

**Teste de Contexto (Segunda Mensagem):**

Envie uma segunda mensagem usando o **mesmo `user_id`** para testar se o assistente lembra do t√≥pico anterior:

```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/chat' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "user_id": "dev_001",
  "message": "E qual deles o FastAPI usa por padr√£o para definir o corpo da requisi√ß√£o?"
}'
```

A resposta deve fazer refer√™ncia ao Pydantic, confirmando que o contexto foi mantido.

### 2. Rota de Limpeza de Hist√≥rico: `/chat/{user_id}` (DELETE)

**Endpoint:** `DELETE /chat/{user_id}`

**Descri√ß√£o:** Limpa o hist√≥rico de chat de um usu√°rio espec√≠fico, for√ßando o in√≠cio de uma nova conversa.

**Exemplo de Teste com `curl`:**

```bash
curl -X 'DELETE' \
  'http://127.0.0.1:8000/chat/dev_001' \
  -H 'accept: application/json'
```

### 3. Rota de Status: `/status` (GET)

**Endpoint:** `GET /status`

**Descri√ß√£o:** Verifica o status da API e se o cliente Gemini foi inicializado corretamente.

## üìÇ Estrutura M√≠nima do Projeto

```
fastapi_llm_assistant/
‚îú‚îÄ‚îÄ .env                  # Vari√°vel de ambiente com a chave GEMINI_API_KEY
‚îú‚îÄ‚îÄ main.py               # C√≥digo principal da aplica√ß√£o FastAPI
‚îú‚îÄ‚îÄ requirements.txt      # Lista de depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md             # Este arquivo
```

## ‚ö†Ô∏è Tratamento de Erros

A API inclui tratamento b√°sico de erros:

*   **503 Service Unavailable:** Retornado se a `GEMINI_API_KEY` n√£o estiver configurada ou se o cliente Gemini falhar ao inicializar.
*   **500 Internal Server Error:** Retornado em caso de falha na comunica√ß√£o com a API do Gemini (ex: chave inv√°lida, limite de taxa excedido).
*   **404 Not Found:** Retornado ao tentar limpar o hist√≥rico de um `user_id` inexistente.
*   **422 Unprocessable Entity:** Erro padr√£o do FastAPI para valida√ß√£o de dados (se o JSON de entrada estiver incorreto).
